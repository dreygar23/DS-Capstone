{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os \n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "import datetime\n",
    "from pandasql import sqldf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Import and DF Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function imports file and creates df with additional column needed for analysis\n",
    "def import_file(file_path):\n",
    "    \n",
    "    #Move directories to find file\n",
    "    os.getcwd()\n",
    "    os.chdir('../data')\n",
    "\n",
    "    \n",
    "    #Read excel file and drop unnecessary column\n",
    "    data = pd.read_excel(file_path)\n",
    "    data.drop('Unnamed: 0', axis=1, inplace = True)\n",
    "    #Add the 'course_term' column to df\n",
    "    data['course_term'] = data['unique_course'] + data['enrl_term_id'].astype(str)\n",
    "    \n",
    "    # Remove any Spring 2020 P grades as these are not reliable\n",
    "    data['remove'] = data[['enrl_term_id', 'CRS_GRADE']].apply(lambda x: True if (x['enrl_term_id'] == 202001 and x['CRS_GRADE'] == 'P') else False, axis = 1)\n",
    "    data_filtered = data.loc[data[\"remove\"] != True].copy()\n",
    "    data_filtered.drop('remove', axis=1, inplace=True)\n",
    "    \n",
    "    return data_filtered\n",
    "\n",
    "\n",
    "#Function creates two dfs that will be used for course identification and student historical file creation\n",
    "def create_dfs(df):\n",
    "    \n",
    "    #Exclude 202108 because at the time file was received, grades for Fall 2021 had not been released\n",
    "    semester_list = [201901, 201905, 201908, 202001, 202005, 202008, 202101, 202105]\n",
    "    filtered_df = df.loc[df['enrl_term_id'].isin(semester_list)]\n",
    "    \n",
    "    #Create a grouping by course to identify high enrollment courses\n",
    "    crs_groups = filtered_df.groupby(['unique_course']).agg({'uuid': ['nunique']})\n",
    "    crs_groups.columns = crs_groups.columns.droplevel(0)\n",
    "    crs_groups = crs_groups.reset_index(inplace=False)\n",
    "    \n",
    "    #Sort the above df and keep only the first 25 courses (high enrollment) \n",
    "    crs_groups.sort_values(by=['nunique'], inplace=True, ascending=False)\n",
    "    high_enrollment = crs_groups.head(25)\n",
    "    \n",
    "    #Create a simplified df with only the columns that strictly necessary to identify course-term-student \n",
    "    #combinations\n",
    "    data_simplified = df[['uuid', 'unique_course', 'enrl_term_id', 'course_term', 'crs_avg_grd_term', \n",
    "                          'CRS_GRADE', 'grade_point_value']]\n",
    "    \n",
    "    return filtered_df, high_enrollment, data_simplified \n",
    "\n",
    "\n",
    "# Helper function to help calculate the historical grade avg per course\n",
    "def course_avg(avg_grade, terms):\n",
    "    \n",
    "    return avg_grade / terms\n",
    "\n",
    "\n",
    "# Helper function to help calculate the pass/fail status of a student/course pairing\n",
    "def pf_flag(grade): \n",
    "    if grade in ['A', 'A-', 'AU', 'B', 'B+', 'B-', 'C', 'C+', 'C-', 'P']: \n",
    "        return 'pass'\n",
    "    return 'fail'\n",
    "\n",
    "# Helper function to get year from term\n",
    "# This works because python uses floor division (will always round down to nearest int, giving me right year)\n",
    "def remove_last_two(num): \n",
    "    return (num // 100)\n",
    "\n",
    "\n",
    "# Helper function to calculate the difference between two columns\n",
    "# Used to calculate the years elapsed\n",
    "def difference(a,b):\n",
    "    return a - b\n",
    "\n",
    "# Helper function to flag the row containing the latest term in which a course is taken    \n",
    "def keep_latest(enrl_term, latest_term):\n",
    "    is_latest = False\n",
    "    if enrl_term == latest_term:\n",
    "        is_latest = True\n",
    "    return is_latest\n",
    "\n",
    "\n",
    "# Function to calculate UCC data\n",
    "def calc_ucc(df):\n",
    "    \n",
    "    # Create a df to hold only those rows with UCC courses\n",
    "    filtered = df.loc[df['UCC_CRSE_FLG'] == 'Y']\n",
    "    \n",
    "    # Find the latest term the UCC course was taken in (use this to determine pass/fail)\n",
    "    latest_term_UCC = filtered.groupby(['uuid', 'unique_course']).agg({'enrl_term_id': ['max']}).rename(columns={'max':'latest_term'})\n",
    "    latest_term_UCC.columns = latest_term_UCC.columns.droplevel(0)\n",
    "    latest_term_UCC = latest_term_UCC.reset_index(inplace=False)\n",
    "\n",
    "    # Merge into filtered file with all data (pertaining to only UCC courses)\n",
    "    UCC_latest = pd.merge(filtered, latest_term_UCC, how='left', on=['uuid', 'unique_course'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    # Create attribute to identify the row with the latest grade for UCC course (based on latest term)\n",
    "    UCC_latest['is_latest_grade']  = UCC_latest.apply(lambda x: keep_latest(x['enrl_term_id'],x['latest_term']), axis=1)\n",
    "\n",
    "    # Create a df with UCC Courses and only the latest grades\n",
    "    UCC_ = UCC_latest.loc[UCC_latest['is_latest_grade'] == True]\n",
    "    \n",
    "    # Calculate the # of UCCs taken\n",
    "    taken_UCC = UCC_.groupby(['uuid']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'UCCs_taken'})\n",
    "    taken_UCC.columns = taken_UCC.columns.droplevel(0)\n",
    "    taken_UCC = taken_UCC.reset_index(inplace=False)\n",
    "    \n",
    "    # Calculate pass/fail for UCCs\n",
    "    Pass_Fail_UCC = UCC_.groupby(['uuid', 'Pass_Fail']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'unique_courses'})\n",
    "    Pass_Fail_UCC.columns = Pass_Fail_UCC.columns.droplevel(0)\n",
    "    Pass_Fail_UCC = Pass_Fail_UCC.reset_index(inplace=False)\n",
    "    \n",
    "    # Pivot rows to columns to prepare for merging to main file\n",
    "    pivoted_UCC_PF = Pass_Fail_UCC.pivot(index='uuid', columns='Pass_Fail', values='unique_courses').reset_index()\n",
    "    pivoted_UCC_PF.columns.name=None\n",
    "    pivoted_UCC_PF.rename(columns = {'fail': 'UCCs_failed', 'pass':'UCCs_passed'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Merge data back into main dataframe\n",
    "    merge_1 = pd.merge(df, taken_UCC, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "\n",
    "    main_UCC = pd.merge(merge_1, pivoted_UCC_PF, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    return main_UCC\n",
    "    \n",
    "    \n",
    "    \n",
    "# Function to calculate gateway data\n",
    "def calc_gateway(df):\n",
    "    \n",
    "    # Create a df to hold only those rows with gateway courses\n",
    "    filtered = df.loc[df['GATEWAYCRSE_FLG'] == 'Y']\n",
    "    \n",
    "    # Find the latest term the gateway course was taken in (use this to determine pass/fail)\n",
    "    latest_term_gate = filtered.groupby(['uuid', 'unique_course']).agg({'enrl_term_id': ['max']}).rename(columns={'max':'latest_term'})\n",
    "    latest_term_gate.columns = latest_term_gate.columns.droplevel(0)\n",
    "    latest_term_gate = latest_term_gate.reset_index(inplace=False)\n",
    "\n",
    "    # Merge into filtered file with all data (pertaining to only gateway courses)\n",
    "    gateway_latest = pd.merge(filtered, latest_term_gate, how='left', on=['uuid', 'unique_course'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    # Create attribute to identify the row with the latest grade for gateway course (based on latest term)\n",
    "    gateway_latest['is_latest_grade']  = gateway_latest.apply(lambda x: keep_latest(x['enrl_term_id'],x['latest_term']), axis=1)\n",
    "\n",
    "    # Create a df with gateway Courses and only the latest grades\n",
    "    gateway_ = gateway_latest.loc[gateway_latest['is_latest_grade'] == True]\n",
    "    \n",
    "    # Calculate the # of gateways taken\n",
    "    taken_gate = gateway_.groupby(['uuid']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'gateways_taken'})\n",
    "    taken_gate.columns = taken_gate.columns.droplevel(0)\n",
    "    taken_gate = taken_gate.reset_index(inplace=False)\n",
    "    \n",
    "    # Calculate pass/fail for gateways\n",
    "    Pass_Fail_gate = gateway_.groupby(['uuid', 'Pass_Fail']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'unique_courses'})\n",
    "    Pass_Fail_gate.columns = Pass_Fail_gate.columns.droplevel(0)\n",
    "    Pass_Fail_gate = Pass_Fail_gate.reset_index(inplace=False)\n",
    "    \n",
    "    # Pivot rows to columns to prepare for merging to main file\n",
    "    pivoted_gate_PF = Pass_Fail_gate.pivot(index='uuid', columns='Pass_Fail', values='unique_courses').reset_index()\n",
    "    pivoted_gate_PF.columns.name=None\n",
    "    pivoted_gate_PF.rename(columns = {'fail': 'gateways_failed', 'pass':'gateways_passed'}, inplace = True)\n",
    "    \n",
    "    \n",
    "    # Merge data back into main dataframe\n",
    "    merge_1 = pd.merge(df, taken_gate, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "\n",
    "    main_gateway = pd.merge(merge_1, pivoted_gate_PF, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    return main_gateway \n",
    "\n",
    "\n",
    "# Function to calculate general pass/fail counts per term\n",
    "def calc_pf_term(df):\n",
    "    \n",
    "    #Create a temporary dataframe\n",
    "    temp2 = df.copy()\n",
    "    \n",
    "    # Calculate the # of courses taken per term\n",
    "    taken_by_term = temp2.groupby(['uuid', 'enrl_term_id']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'term_courses_taken'})\n",
    "    taken_by_term.columns = taken_by_term.columns.droplevel(0)\n",
    "    taken_by_term = taken_by_term.reset_index(inplace=False)\n",
    "\n",
    "    # Calculate the number of courses passed vs failed in term\n",
    "    Pass_Fail_term = temp2.groupby(['uuid','enrl_term_id' ,'Pass_Fail']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'unique_courses'})\n",
    "    Pass_Fail_term.columns = Pass_Fail_term.columns.droplevel(0)\n",
    "    Pass_Fail_term = Pass_Fail_term.reset_index(inplace=False)\n",
    "    \n",
    "    # Pivot rows to columns to prepare for merging to main file\n",
    "    pivoted_term = Pass_Fail_term.pivot(index=['uuid', 'enrl_term_id'], columns='Pass_Fail', values='unique_courses').reset_index()\n",
    "    pivoted_term.columns.name=None\n",
    "    pivoted_term.rename(columns = {'fail': 'term_courses_failed', 'pass':'term_courses_passed'}, inplace = True)\n",
    "\n",
    "    # Merge attributes back into main dataframe\n",
    "    merge_term_1 = pd.merge(df, taken_by_term, how='left', on=['uuid', 'enrl_term_id'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "\n",
    "    final = pd.merge(merge_term_1, pivoted_term, how='left', on=['uuid', 'enrl_term_id'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    return final\n",
    "\n",
    "\n",
    "# Function to calculate general pass/fail counts overall\n",
    "def calc_pf(df):\n",
    "    \n",
    "    #Create a temporary dataframe\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # Find the latest term the course was taken in (use this to determine pass/fail)\n",
    "    latest_term_all = temp.groupby(['uuid', 'unique_course']).agg({'enrl_term_id': ['max']}).rename(columns={'max':'latest_term'})\n",
    "    latest_term_all.columns = latest_term_all.columns.droplevel(0)\n",
    "    latest_term_all = latest_term_all.reset_index(inplace=False)\n",
    "    \n",
    "    # Merge into filtered file with all data (pertaining to all courses)\n",
    "    all_latest = pd.merge(temp, latest_term_all, how='left', on=['uuid', 'unique_course'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    # Create attribute to identify the row with the latest grade for course (based on latest term)\n",
    "    all_latest['is_latest_grade']  = all_latest.apply(lambda x: keep_latest(x['enrl_term_id'],x['latest_term']), axis=1)\n",
    "    \n",
    "    # Create a df with all Courses and only the latest grades\n",
    "    all_ = all_latest.loc[all_latest['is_latest_grade'] == True]\n",
    "    \n",
    "    # Calculate the # of courses taken\n",
    "    taken_ = all_.groupby(['uuid']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'total_courses_taken'})\n",
    "    taken_.columns = taken_.columns.droplevel(0)\n",
    "    taken_ = taken_.reset_index(inplace=False)\n",
    "    \n",
    "    # Calculate the number of courses passed vs failed\n",
    "    Pass_Fail_all = all_.groupby(['uuid', 'Pass_Fail']).agg({'unique_course': ['nunique']}).rename(columns={'nunique':'unique_courses'})\n",
    "    Pass_Fail_all.columns = Pass_Fail_all.columns.droplevel(0)\n",
    "    Pass_Fail_all = Pass_Fail_all.reset_index(inplace=False)\n",
    "\n",
    "    # Pivot rows to columns to prepare for merging to main file\n",
    "    pivoted_all = Pass_Fail_all.pivot(index='uuid', columns='Pass_Fail', values='unique_courses').reset_index()\n",
    "    pivoted_all.columns.name=None\n",
    "    pivoted_all.rename(columns = {'fail': 'total_courses_failed', 'pass':'total_courses_passed'}, inplace = True)\n",
    "    \n",
    "    # Merge data back into main dataframe\n",
    "    main_ = pd.merge(df, pivoted_all, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    return main_\n",
    "\n",
    "\n",
    "# Removes duplicate course/grade instances per student and keeps only latest grade per course\n",
    "def remove_retakes (df_course):\n",
    "    \n",
    "    #Make copy of df_course\n",
    "    course_data = df_course.copy()\n",
    "    \n",
    "    # Find the latest term the course was taken in (use this to remove past retakes)\n",
    "    latest_term = df_course.groupby(['uuid', 'unique_course']).agg({'enrl_term_id': ['max']}).rename(columns={'max':'latest_term'})\n",
    "    latest_term.columns = latest_term.columns.droplevel(0)\n",
    "    latest_term = latest_term.reset_index(inplace=False)\n",
    "\n",
    "    # Merge into file with all data\n",
    "    all_ = pd.merge(course_data, latest_term, how='left', on=['uuid', 'unique_course'],\n",
    "         suffixes=('_og', '_stu'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    # Create attribute to identify the row with the latest grade for course (based on latest term)\n",
    "    all_['is_latest_grade']  = all_.apply(lambda x: keep_latest(x['enrl_term_id'],x['latest_term']), axis=1)\n",
    "\n",
    "    # Create a df with Courses and only the latest grades\n",
    "    latest_only = all_.loc[all_['is_latest_grade'] == True]\n",
    "    \n",
    "    return latest_only\n",
    "        \n",
    "    \n",
    "# Creates the course attributes for analysis for train data\n",
    "def calc_crs_vars_train(df_data, df_course):    \n",
    "    \n",
    "    # Identify Course/term pairings found in train data\n",
    "    crs_term = df_course.groupby(['unique_course', 'enrl_term_id'], as_index=False).agg({'uuid':['nunique']})\n",
    "    crs_term.columns = crs_term.columns.get_level_values(0)\n",
    "    \n",
    "    # Create list of terms\n",
    "    term_list = crs_term['enrl_term_id'].tolist()\n",
    "    \n",
    "    # Create list to house course vars \"arrays\"\n",
    "    crs_vars_train = []\n",
    "    \n",
    "    for term in term_list:\n",
    "    \n",
    "        # Filter df to include only info prior to specified term\n",
    "        filtered = df_data.loc[((df_data['enrl_term_id'] <= term) & (df_data['unique_course'] == df_course['unique_course'].values[0]))] \n",
    "\n",
    "        # Group df by course, term and crs_avg_grade\n",
    "        df_1 = filtered.groupby(['unique_course', 'enrl_term_id','crs_avg_grd_term'], as_index=False).agg({'uuid':['nunique']})\n",
    "        df_1.columns = df_1.columns.get_level_values(0)\n",
    "\n",
    "        # Sum total course avg grades and count number of terms course has been taught\n",
    "        df_2 = df_1.groupby(['unique_course'], as_index = False).agg({'enrl_term_id':['nunique'], 'crs_avg_grd_term':['sum']})\n",
    "        df_2.columns = df_2.columns.get_level_values(0)\n",
    "\n",
    "        # Calculate avg course grade historically (only accounting for data included in filtered df)\n",
    "        df_2['crs_avg_grade_all'] = df_2[['enrl_term_id', 'crs_avg_grd_term']].apply(lambda x: course_avg(x['crs_avg_grd_term'], x['enrl_term_id']), axis = 1)\n",
    "        df_2 = df_2.rename(columns={'enrl_term_id': 'tot_terms_tgt'})\n",
    "        df_2.drop(['crs_avg_grd_term'], axis = 1, inplace = True)\n",
    "        \n",
    "        # Create 'array' and append to list\n",
    "        row = [df_2['unique_course'].values[0], term, df_2['tot_terms_tgt'].values[0], df_2['crs_avg_grade_all'].values[0]]\n",
    "        #Append to main list_course_dets\n",
    "        crs_vars_train.append(row)\n",
    "        \n",
    "    \n",
    "    #return df with crs_avg_grade_all as well as tot_terms_taught\n",
    "    final_vars = pd.DataFrame(crs_vars_train, columns = ['unique_course', 'enrl_term_id', 'tot_terms_tgt',\n",
    "                                                    'crs_avg_grade_all'])\n",
    "    \n",
    "    \n",
    "    return final_vars\n",
    "\n",
    "\n",
    "# Creates the course attributes for analysis\n",
    "def calc_crs_vars(df, term, course):\n",
    "    \n",
    "    #Filter df to include only info prior to specified term\n",
    "    filtered = df.loc[((df['enrl_term_id'] <= term)) & (df['unique_course'] == course)] \n",
    "    \n",
    "    # Group df by course, term and crs_avg_grade\n",
    "    df_1 = filtered.groupby(['unique_course', 'enrl_term_id','crs_avg_grd_term'], as_index=False).agg({'uuid':['nunique']})\n",
    "    df_1.columns = df_1.columns.get_level_values(0)\n",
    "    \n",
    "    # Sum total course avg grades and count number of terms course has been taught\n",
    "    df_2 = df_1.groupby(['unique_course'], as_index = False).agg({'enrl_term_id':['nunique'], 'crs_avg_grd_term':['sum']})\n",
    "    df_2.columns = df_2.columns.get_level_values(0)\n",
    "    \n",
    "    # Calculate avg course grade historically (only accounting for data included in filtered df)\n",
    "    df_2['crs_avg_grade_all'] = df_2[['enrl_term_id', 'crs_avg_grd_term']].apply(lambda x: course_avg(x['crs_avg_grd_term'], x['enrl_term_id']), axis = 1)\n",
    "    df_2 = df_2.rename(columns={'enrl_term_id': 'tot_terms_tgt'})\n",
    "    df_2.drop(['crs_avg_grd_term'], axis = 1, inplace = True)\n",
    "    \n",
    "    #return df with crs_avg_grade_all as well as tot_terms_taught\n",
    "    return df_2\n",
    "    \n",
    "    \n",
    "# Creates the student attributes for analysis    \n",
    "def calc_stu_vars(df):\n",
    "    \n",
    "    # Group df by student, term and creds attempted\n",
    "    df_1 = df.groupby(['uuid', 'enrl_term_id','creds_attp_term'], as_index=False).agg({'unique_course':['nunique']})\n",
    "    df_1.columns = df_1.columns.get_level_values(0)\n",
    "    \n",
    "    # Sum total creds earned and count number of terms student has been enrolled\n",
    "    df_2 = df_1.groupby(['uuid'], as_index=False).agg({'enrl_term_id':['nunique'], 'creds_attp_term':['sum']})\n",
    "    df_2.columns = df_2.columns.get_level_values(0)\n",
    "    df_2 = df_2.rename(columns={'enrl_term_id': 'tot_terms_enrled', 'creds_attp_term':'creds_attp_all'})\n",
    "    \n",
    "    #return df with total creds earned and total terms enrolled per student\n",
    "    return df_2\n",
    "\n",
    "# Creates enrollment-based attributes for analysis\n",
    "def calc_enrl_vars(df):\n",
    "  \n",
    "    # Create new attribute based on pass/fail function that uses course grade\n",
    "    df['Pass_Fail'] = df['CRS_GRADE'].apply(pf_flag)\n",
    "    \n",
    "    #Find the minimun enrollment term per uuid, keep only relevant columns to then merge back to main df\n",
    "    #Create temp df to save results\n",
    "    min_enrl_term = df.loc[df.groupby('uuid')['enrl_term_id'].idxmin()][['uuid', 'enrl_term_id']]\n",
    "    \n",
    "    #Rename columns\n",
    "    min_enrl_term = min_enrl_term.rename(columns={'enrl_term_id': 'min_enrl_term'})\n",
    "    \n",
    "    # Add minimum enrollment term to main file\n",
    "    df_min = pd.merge(df, min_enrl_term, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_min'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    #Find the maximum enrollment term per EMPLID, keep only relevant columns to then merge back to main df\n",
    "    #Create temp df to save results\n",
    "    max_enrl_term = df_min.loc[df_min.groupby('uuid')['enrl_term_id'].idxmax()][['uuid', 'enrl_term_id']]\n",
    "    \n",
    "    #Rename columns\n",
    "    max_enrl_term = max_enrl_term.rename(columns={'enrl_term_id': 'max_enrl_term'})\n",
    "    \n",
    "    # Add maximum enrollment term to main file\n",
    "    df_max = pd.merge(df_min, max_enrl_term, how='left', on=['uuid'],\n",
    "         suffixes=('_og', '_min'), copy=True, indicator=False,\n",
    "         validate=None)\n",
    "    \n",
    "    #Create an minimum enrollment year column to calculate elapsed time\n",
    "    df_max['min_enrl_year'] = df_max['min_enrl_term'].apply(remove_last_two)\n",
    "    \n",
    "    # Create a maximum enrollment year column to calculate elapsed time\n",
    "    df_max['max_enrl_year'] = df_max['max_enrl_term'].apply(remove_last_two)\n",
    "    \n",
    "    # Create time_elapsed attribute by finding difference between min and max enrollment years\n",
    "    df_max['time_elapsed']  = df_max.apply(lambda x: difference(x['max_enrl_year'],x['min_enrl_year']), axis=1)\n",
    "    \n",
    "    #Calculate UCC-related vars\n",
    "    df_ucc = calc_ucc(df_max)\n",
    "    \n",
    "    #Calculate gateway-related vars\n",
    "    df_gateway = calc_gateway(df_ucc)\n",
    "    \n",
    "    #Calculate general pass/fail\n",
    "    df_pf = calc_pf(df_gateway)\n",
    "    \n",
    "    return df_pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify terms available for Course & Create Student Historical Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with chosen courses, latest available term, second to last available term\n",
    "# and previous term (in relation to second to last term)\n",
    "# Returns dictionaries of dataframes with student uuids for each course/term\n",
    "def create_course_details(course_summ_df, years_df, data_file):\n",
    "    \n",
    "    course_list = course_summ_df['unique_course'].tolist()\n",
    "    \n",
    "    list_course_dets = []\n",
    "    latest = {}\n",
    "    sectl = {} #second to last\n",
    "    thirdtl = {} #third to last\n",
    "    \n",
    "    for course in course_list:\n",
    "        \n",
    "        # Create a filtered df per course\n",
    "        course_df = years_df.loc[years_df['unique_course'] == course]\n",
    "        \n",
    "        # Create a summary df of the terms this course was taught (based on the enrollments)\n",
    "        terms_summ_df = course_df.groupby(course_df['enrl_term_id']).agg({'uuid': ['nunique']})\n",
    "        terms_summ_df.columns = terms_summ_df.columns.droplevel(0)\n",
    "        terms_summ_df = terms_summ_df.reset_index(inplace=False)\n",
    "        \n",
    "        # Calculate the \"rank\" of each enrl_term_id to determine the last three terms in data per course\n",
    "        terms_summ_df['rank'] = terms_summ_df['enrl_term_id'].rank()\n",
    "        \n",
    "        #Check that max_rank is >= 3\n",
    "        max_rank = terms_summ_df['rank'].max()\n",
    "        \n",
    "        if max_rank < 3:\n",
    "            continue\n",
    "        else:\n",
    "            #Find latest term\n",
    "            latest_term = terms_summ_df.loc[terms_summ_df['rank'] == max_rank]['enrl_term_id'].values[0]\n",
    "            \n",
    "            #Find second to last term (in relation to latest term)\n",
    "            sec_to_last_term = terms_summ_df.loc[terms_summ_df['rank'] == max_rank - 1]['enrl_term_id'].values[0]\n",
    "            #Find previous term (prev in relation to second to last term)\n",
    "            prev_term = terms_summ_df.loc[terms_summ_df['rank'] == max_rank - 2]['enrl_term_id'].values[0]\n",
    "            \n",
    "            #Creating df per course for each term (latest, second to latest, prev term)\n",
    "            latest_df = data_file.loc[(data_file['unique_course'] == course) & \n",
    "                                (data_file['enrl_term_id'] == latest_term)]\n",
    "            stl_df = data_file.loc[(data_file['unique_course'] == course) & \n",
    "                                (data_file['enrl_term_id'] == sec_to_last_term)]\n",
    "            prev_df = data_file.loc[(data_file['unique_course'] == course) & \n",
    "                                (data_file['enrl_term_id'] <= prev_term)] \n",
    "            \n",
    "            \n",
    "            #Remove retakes from train data\n",
    "            prev_df_nr = remove_retakes(prev_df)\n",
    "            \n",
    "            #Calculate # of times course taught & course avg grade historical\n",
    "            late = calc_crs_vars(data_file, latest_term, course)\n",
    "            slate = calc_crs_vars(data_file, sec_to_last_term, course)\n",
    "            tlate = calc_crs_vars_train(data_file, prev_df_nr) \n",
    "                \n",
    "            #Merge into df created per course above\n",
    "            latest_final = pd.merge(latest_df, late[['unique_course','tot_terms_tgt', 'crs_avg_grade_all']], \n",
    "                                    how='left', on=['unique_course'], suffixes=('_og', '_stu')\n",
    "                                    ,copy=True, indicator=False,validate=None)\n",
    "\n",
    "            stl_final = pd.merge(stl_df, slate[['unique_course','tot_terms_tgt', 'crs_avg_grade_all']], \n",
    "                                    how='left', on=['unique_course'], suffixes=('_og', '_stu')\n",
    "                                    ,copy=True, indicator=False,validate=None)\n",
    "            \n",
    "            prev_final = pd.merge(prev_df_nr, tlate[['unique_course','enrl_term_id','tot_terms_tgt', 'crs_avg_grade_all']], \n",
    "                                    how='left', on=['unique_course', 'enrl_term_id'], suffixes=('_og', '_stu')\n",
    "                                    ,copy=True, indicator=False,validate=None)\n",
    "            \n",
    "            #Remove unwanted columns from train data df\n",
    "            prev_final.drop(['is_latest_grade','latest_term'], axis = 1, inplace = True)\n",
    "            \n",
    "            #Appending the dfs to a dictionary (according to term snapshot)\n",
    "            latest[course] = latest_final\n",
    "            sectl[course] = stl_final\n",
    "            thirdtl[course] = prev_final\n",
    "            \n",
    "            #Create temp list of course details  \n",
    "            course_dets = [course, latest_term, sec_to_last_term, prev_term]\n",
    "            #Append to main list_course_dets\n",
    "            list_course_dets.append(course_dets)\n",
    "        \n",
    "    \n",
    "    data = pd.DataFrame(list_course_dets, columns = ['Unique Course', 'Latest Term', 'Second to Last Term',\n",
    "                                                    'Third from Last Term'])\n",
    "    \n",
    "    return data, latest, sectl, thirdtl\n",
    "     \n",
    "    \n",
    "\n",
    "# This function will take as input four params and create a dictionary \n",
    "# to house dfs with student historical data\n",
    "'''\n",
    "param1: This is the list of courses that were identified as having high enrollment\n",
    "param2: This is the dictionary that corresponds to the set of data that will be examined\n",
    "param3: This is the df housing the full data set from which historical data will be extracted\n",
    "'''\n",
    "def collect_student_hist(high_enrl_crs, crs_dict, full_data_file):\n",
    "    \n",
    "    course_list = high_enrl_crs['Unique Course'].tolist()\n",
    "    \n",
    "    student_hist_data = {}\n",
    "    \n",
    "    for course in course_list:\n",
    "        \n",
    "        #Get term that will serve as limit for obtaining student historical data\n",
    "        #term = crs_dict[course]['enrl_term_id'].values[0]\n",
    "        \n",
    "        #Create empty df to save student files per term\n",
    "        #students = pd.DataFrame(columns = list(full_data_file.columns.values))\n",
    "        students = pd.DataFrame()\n",
    "        \n",
    "        #Get list of terms that course was taught in\n",
    "        term_list = crs_dict[course]['enrl_term_id'].unique().tolist()\n",
    "        \n",
    "        for term in term_list:\n",
    "            #print(course, \" \", term)\n",
    "            #Create copy of df that holds the information for this specific course/term pairing\n",
    "            course_df = crs_dict[course].copy()\n",
    "            #print(course_df)\n",
    "            course_filtered = course_df.loc[course_df['enrl_term_id'] == term]\n",
    "            \n",
    "            course_final = course_filtered[['uuid','unique_course','tot_terms_tgt','crs_avg_grd_term', 'crs_avg_grade_all', \n",
    "                                   'CRS_GRADE', 'grade_point_value']]\n",
    "            course_final = course_final.rename(columns={'unique_course': 'target_crs', 'tot_terms_tgt':'target_terms_tgt',\n",
    "                                     'crs_avg_grd_term':'target_avg_grd_term', 'crs_avg_grade_all':'target_avg_grade_all',\n",
    "                                     'CRS_GRADE':'target_crs_grade', 'grade_point_value':'target_gpv'})\n",
    "\n",
    "            #Get the list of students enrolled in the course (for specified term)\n",
    "            students_enrl = course_final['uuid'].tolist()\n",
    "            \n",
    "                \n",
    "\n",
    "            #Get the historical data for the students enrolled in term\n",
    "            student_df = full_data_file.loc[(full_data_file['uuid'].isin(students_enrl)) & \n",
    "                                    (full_data_file['enrl_term_id'] < term) & \n",
    "                                    (full_data_file['unique_course'] != course)]\n",
    "            \n",
    "            if student_df.empty == False:\n",
    "                \n",
    "                #Calculate terms taken and total credits attempted and merge back to main file\n",
    "                to_merge = calc_stu_vars(student_df)\n",
    "                student_mid = pd.merge(student_df, to_merge[['uuid','tot_terms_enrled', 'creds_attp_all']], \n",
    "                                            how='left', on=['uuid'], suffixes=('_og', '_stu')\n",
    "                                            ,copy=True, indicator=False,validate=None)\n",
    "                \n",
    "                #Keep only those students who have been enrolled for two terms or more\n",
    "                student_mid_2 = student_mid.loc[student_mid['tot_terms_enrled'] >= 2].copy()\n",
    "                \n",
    "                if student_mid_2.empty == False:\n",
    "                \n",
    "                    #Calculate additional student course enrollment attributes\n",
    "\n",
    "                    student_final = calc_enrl_vars(student_mid_2)\n",
    "\n",
    "                    stu_crs = pd.merge(student_final, course_final, \n",
    "                                                how='left', on=['uuid'], suffixes=('_og', '_stu')\n",
    "                                                ,copy=True, indicator=False,validate=None)\n",
    "\n",
    "                    #Union dataframe with other terms' student lists\n",
    "                    students = students.append(stu_crs)\n",
    "                    students_noretakes = remove_retakes(students) \n",
    "                else: \n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        #Append df to dictionary\n",
    "        student_hist_data[course] = students_noretakes\n",
    "        \n",
    "        \n",
    "    return student_hist_data\n",
    "\n",
    "\n",
    "# Function to create the historical enrollment files for students enrolled in course of interest\n",
    "def create_student_files(courses_, tr, va, te):\n",
    "    \n",
    "    course_list = courses_['Unique Course'].tolist()\n",
    "    \n",
    "    for course in course_list:\n",
    "        \n",
    "        course_name = course.replace(\"-\", \"\")\n",
    "\n",
    "        with pd.ExcelWriter('files/{}.xlsx'.format(course_name)) as writer:\n",
    "            train[course].to_excel(writer, sheet_name='train')\n",
    "            validate[course].to_excel(writer, sheet_name='validate')\n",
    "            test[course].to_excel(writer, sheet_name='test')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Execute code to identify high enrollment courses, find their latest, second to latest and third to latest terms\n",
    "# Find the students enrolled in each of those terms\n",
    "# Find each student's historical enrollment data and export to excel to use for model building\n",
    "def run_script():\n",
    "    # Import file\n",
    "    full = import_file(\"anon_engvars_01232022.xlsx\")\n",
    "    print(\"Data imported\")\n",
    "    \n",
    "    # Create the necessary dfs for analysis\n",
    "    df_19_21, high_enrl_crs, simple_data = create_dfs(full)\n",
    "    print(\"Dataframes created\")\n",
    "    \n",
    "    # Create dictionaries of dataframes with student uuids for each course/term\n",
    "    courses_dets, latest, stl, ttl = create_course_details(high_enrl_crs, df_19_21, simple_data)\n",
    "    print(\"Dictionaries created\")\n",
    "        \n",
    "    # Create subsets of data containing students previous terms enrollment\n",
    "    train = collect_student_hist(courses_dets, ttl, full)\n",
    "    validate = collect_student_hist(courses_dets, stl, full)\n",
    "    test = collect_student_hist(courses_dets, latest, full)\n",
    "    print(\"Train, Validate and Test subsets created\")\n",
    "    \n",
    "    # Export historical enrollment files per course to excel\n",
    "    create_student_files(courses_dets, train, validate, test)\n",
    "    print(\"Historical enrollment files exported to excel!\")\n",
    "    \n",
    "    print(\"Successful!\")\n",
    "    \n",
    "    return full, df_19_21, high_enrl_crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Script and Create Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported\n",
      "Dataframes created\n",
      "Dictionaries created\n",
      "Train, Validate and Test subsets created\n",
      "Historical enrollment files exported to excel!\n",
      "Successful!\n"
     ]
    }
   ],
   "source": [
    " full, df_19_21, high_enrl_crs = run_script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_course</th>\n",
       "      <th>nunique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>PSY-3211-</td>\n",
       "      <td>3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>PSY-3024-</td>\n",
       "      <td>2963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>PSY-3215-</td>\n",
       "      <td>2413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>PSY-4931-</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>MAR-3023-</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>ENC-1102-</td>\n",
       "      <td>1754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>EAB-3002-</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>QMB-3200-</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>COM-3112-</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>MAN-3025-</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>FIN-3403-</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>DEP-3305-</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>GEB-3003-</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>QMB-4680-</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>ISM-3011-</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>CCJ-4014-</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>EXP-3523-</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>BUL-4310-</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>CCJ-3628-</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>MAN-4720-</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>SOP-3004-</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>CLP-4146-</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>BSC-2023-</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>CJL-4064-</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>CLP-4374-</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_course  nunique\n",
       "1835     PSY-3211-     3176\n",
       "1834     PSY-3024-     2963\n",
       "1836     PSY-3215-     2413\n",
       "1842     PSY-4931-     1900\n",
       "1413     MAR-3023-     1830\n",
       "748      ENC-1102-     1754\n",
       "585      EAB-3002-     1723\n",
       "1853     QMB-3200-     1692\n",
       "468      COM-3112-     1685\n",
       "1368     MAN-3025-     1656\n",
       "884      FIN-3403-     1655\n",
       "559      DEP-3305-     1646\n",
       "940      GEB-3003-     1627\n",
       "1854     QMB-4680-     1621\n",
       "1206     ISM-3011-     1617\n",
       "321      CCJ-4014-     1543\n",
       "868      EXP-3523-     1475\n",
       "303      BUL-4310-     1466\n",
       "316      CCJ-3628-     1449\n",
       "1400     MAN-4720-     1442\n",
       "1943     SOP-3004-     1367\n",
       "457      CLP-4146-     1340\n",
       "275      BSC-2023-     1309\n",
       "452      CJL-4064-     1308\n",
       "459      CLP-4374-     1279"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_enrl_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
